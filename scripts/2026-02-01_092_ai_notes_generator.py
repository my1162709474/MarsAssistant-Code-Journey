"""
AIå­¦ä¹ ç¬”è®°ç”Ÿæˆå™¨
ä»ä»£ç ã€æ–‡æ¡£æˆ–æ–‡æœ¬ä¸­æå–å…³é”®æ¦‚å¿µï¼Œç”Ÿæˆç»“æ„åŒ–å­¦ä¹ ç¬”è®°
"""

import re
import json
from typing import List, Dict, Tuple
from collections import Counter


class AINotesGenerator:
    """AIé©±åŠ¨çš„å­¦ä¹ ç¬”è®°ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.keywords = self._load_keywords()
        self.patterns = self._load_patterns()
    
    def _load_keywords(self) -> Dict[str, List[str]]:
        """åŠ è½½å„ç±»ç¼–ç¨‹æ¦‚å¿µå…³é”®è¯"""
        return {
            "æ•°æ®ç»“æ„": ["list", "dict", "set", "tuple", "stack", "queue", "heap", 
                        "tree", "graph", "hash", "linked", "array", "matrix"],
            "ç®—æ³•": ["sort", "search", "recursive", "dynamic", "greedy", "binary",
                    " DFS", "BFS", "dijkstra", "backtrack", "divide", "conquer"],
            "ç¼–ç¨‹æ¦‚å¿µ": ["function", "class", "method", "inheritance", "polymorphism",
                       "encapsulation", "decorator", "generator", "iterator", "closure"],
            "è®¾è®¡æ¨¡å¼": ["singleton", "factory", "observer", "strategy", "adapter",
                       "decorator", "proxy", "template", "command", "state"],
            "AIç›¸å…³": ["neural", "network", "transformer", "attention", "embedding",
                      "token", "prompt", "fine-tune", "inference", "training"]
        }
    
    def _load_patterns(self) -> List[Tuple[str, str]]:
        """åŠ è½½æ³¨é‡Šå’Œæ–‡æ¡£æ¨¡å¼"""
        return [
            (r'#\s*(TODO|FIXME|NOTE|HACK|XXX)\s*:?\s*(.*)', 'æ ‡è®°'),
            (r'"""(.*?)"""', 'æ–‡æ¡£å­—ç¬¦ä¸²'),
            (r'\'\'\'(.*?)\'\'\'', 'æ–‡æ¡£å­—ç¬¦ä¸²'),
            (r'def\s+(\w+)\s*\((.*?)\)', 'å‡½æ•°å®šä¹‰'),
            (r'class\s+(\w+)', 'ç±»å®šä¹‰'),
            (r'#\s*(.+)$', 'æ³¨é‡Š'),
        ]
    
    def extract_concepts(self, text: str) -> Dict[str, List[str]]:
        """ä»æ–‡æœ¬ä¸­æå–æ¦‚å¿µ"""
        concepts = {category: [] for category in self.keywords}
        text_lower = text.lower()
        
        for category, keywords in self.keywords.items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    if keyword not in concepts[category]:
                        concepts[category].append(keyword)
        
        return {k: v for k, v in concepts.items() if v}
    
    def extract_code_elements(self, code: str) -> Dict:
        """æå–ä»£ç å…ƒç´ """
        elements = {
            "functions": [],
            "classes": [],
            "imports": [],
            "comments": []
        }
        
        # æå–å‡½æ•°
        for match in re.finditer(r'def\s+(\w+)\s*\((.*?)\):', code):
            elements["functions"].append({
                "name": match.group(1),
                "params": [p.strip() for p in match.group(2).split(',') if p.strip()]
            })
        
        # æå–ç±»
        for match in re.finditer(r'class\s+(\w+)', code):
            elements["classes"].append(match.group(1))
        
        # æå–å¯¼å…¥
        for match in re.finditer(r'^\s*(?:from|import)\s+(\w+)', code, re.MULTILINE):
            if match.group(1) not in elements["imports"]:
                elements["imports"].append(match.group(1))
        
        # æå–æ³¨é‡Š
        for match in re.finditer(r'#\s*(.+)$', code, re.MULTILINE):
            elements["comments"].append(match.group(1))
        
        return elements
    
    def calculate_complexity(self, code: str) -> Dict:
        """è®¡ç®—ä»£ç å¤æ‚åº¦æŒ‡æ ‡"""
        lines = code.split('\n')
        non_empty = [l for l in lines if l.strip()]
        
        metrics = {
            "total_lines": len(lines),
            "code_lines": len(non_empty),
            "cyclomatic": 1,  # åŸºç¡€å¤æ‚åº¦
            "functions": 0,
            "classes": 0,
            "comment_ratio": 0
        }
        
        code_text = '\n'.join(lines)
        metrics["functions"] = code_text.count('def ')
        metrics["classes"] = code_text.count('class ')
        
        # ç®€å•çš„åœˆå¤æ‚åº¦ä¼°ç®—
        for keyword in ['if ', 'elif ', 'for ', 'while ', 'and ', 'or ', 'except ']:
            metrics["cyclomatic"] += code_text.count(keyword)
        
        comment_count = len(re.findall(r'#', code))
        metrics["comment_ratio"] = round(comment_count / max(len(non_empty), 1), 2)
        
        return metrics
    
    def generate_summary(self, text: str) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ‘˜è¦"""
        sentences = re.split(r'[.!?]', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if not sentences:
            return "æ— æ³•ç”Ÿæˆæ‘˜è¦"
        
        # æ‰¾å‡ºå…³é”®è¯é¢‘ç‡æœ€é«˜çš„å¥å­
        words = re.findall(r'\b\w+\b', text.lower())
        stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',
                    'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',
                    'would', 'could', 'should', 'may', 'might', 'must', 'shall',
                    'can', 'this', 'that', 'these', 'those', 'it', 'its'}
        word_freq = Counter(w for w in words if w not in stopwords and len(w) > 2)
        
        if not word_freq:
            return sentences[0] if sentences else ""
        
        scored = []
        for i, sentence in enumerate(sentences):
            score = sum(word_freq.get(w.lower(), 0) for w in sentence.split())
            scored.append((score, i, sentence))
        
        scored.sort(reverse=True)
        top_sentences = sorted(scored[:3], key=lambda x: x[1])
        
        return ' '.join(s[2] for s in top_sentences)
    
    def generate_notes(self, content: str, title: str = "å­¦ä¹ ç¬”è®°") -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„å­¦ä¹ ç¬”è®°"""
        notes = {
            "title": title,
            "summary": self.generate_summary(content),
            "concepts": self.extract_concepts(content),
            "code_elements": self.extract_code_elements(content),
            "complexity": self.calculate_complexity(content) if content.count('\n') > 1 else {},
            "key_takeaways": [],
            "generated_at": self._timestamp()
        }
        
        # ç”Ÿæˆè¦ç‚¹
        concepts = notes["concepts"]
        if concepts:
            notes["key_takeaways"] = [
                f"å­¦ä¹ é‡ç‚¹ï¼š{', '.join(v)}" for v in concepts.values()
            ][:5]
        
        return notes
    
    def _timestamp(self) -> str:
        """ç”Ÿæˆæ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def export_markdown(self, notes: Dict) -> str:
        """å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
        md = [f"# {notes['title']}\n"]
        md.append(f"> ç”Ÿæˆæ—¶é—´ï¼š{notes['generated_at']}\n")
        
        md.append("\n## ğŸ“‹ æ‘˜è¦\n")
        md.append(f"{notes['summary']}\n")
        
        if notes['concepts']:
            md.append("\n## ğŸ§  æ ¸å¿ƒæ¦‚å¿µ\n")
            for category, items in notes['concepts'].items():
                md.append(f"### {category}\n")
                md.append(f"- " + "\n- ".join(items) + "\n")
        
        if notes['code_elements']['functions']:
            md.append("\n## ğŸ”§ å‡½æ•°\n")
            for func in notes['code_elements']['functions']:
                params = ', '.join(func['params']) if func['params'] else 'æ— å‚æ•°'
                md.append(f"- `{func['name']}({params})`\n")
        
        if notes['code_elements']['classes']:
            md.append("\n## ğŸ“¦ ç±»\n")
            for cls in notes['code_elements']['classes']:
                md.append(f"- `{cls}`\n")
        
        if notes['complexity']:
            md.append("\n## ğŸ“Š ä»£ç æŒ‡æ ‡\n")
            md.append(f"- ä»£ç è¡Œæ•°ï¼š{notes['complexity'].get('code_lines', 'N/A')}\n")
            md.append(f"- å‡½æ•°æ•°é‡ï¼š{notes['complexity'].get('functions', 'N/A')}\n")
            md.append(f"- åœˆå¤æ‚åº¦ï¼š{notes['complexity'].get('cyclomatic', 'N/A')}\n")
        
        if notes['key_takeaways']:
            md.append("\n## ğŸ’¡ å…³é”®è¦ç‚¹\n")
            for take in notes['key_takeaways']:
                md.append(f"- {take}\n")
        
        return '\n'.join(md)
    
    def export_json(self, notes: Dict) -> str:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        return json.dumps(notes, ensure_ascii=False, indent=2)


def demo():
    """æ¼”ç¤º"""
    generator = AINotesGenerator()
    
    # ç¤ºä¾‹ä»£ç 
    sample_code = '''
"""
è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ¨¡å—ï¼Œæ¼”ç¤ºå­¦ä¹ ç¬”è®°ç”Ÿæˆå™¨çš„åŠŸèƒ½
"""
import json
from datetime import datetime

class DataProcessor:
    """æ•°æ®å¤„ç†å™¨ç±»"""
    
    def __init__(self):
        self.data = []
    
    def load_data(self, filename: str) -> bool:
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        try:
            with open(filename, 'r') as f:
                self.data = json.load(f)
            return True
        except Exception:
            return False
    
    def analyze(self) -> Dict:
        """åˆ†ææ•°æ®"""
        return {
            "count": len(self.data),
            "avg": sum(self.data) / len(self.data) if self.data else 0
        }

def quick_sort(arr: List[int]) -> List[int]:
    """å¿«é€Ÿæ’åºç®—æ³•"""
    if len(arr) <= 1:
        return arr
    
    pivot = arr[0]
    left = [x for x in arr[1:] if x < pivot]
    right = [x for x in arr[1:] if x >= pivot]
    
    return quick_sort(left) + [pivot] + quick_sort(right)
    '''
    
    # ç”Ÿæˆç¬”è®°
    notes = generator.generate_notes(sample_code, "æ’åºä¸æ•°æ®ç»“æ„ç¤ºä¾‹")
    
    # è¾“å‡ºMarkdown
    print("=" * 50)
    print("Markdownæ ¼å¼ç¬”è®°ï¼š")
    print("=" * 50)
    print(generator.export_markdown(notes))
    
    print("\n" + "=" * 50)
    print("JSONæ ¼å¼ç¬”è®°ï¼š")
    print("=" * 50)
    print(generator.export_json(notes))


if __name__ == "__main__":
    demo()

#!/usr/bin/env python3
"""
ğŸ“Š Code Statistics Analyzer
ä»£ç ç»Ÿè®¡åˆ†æä»ª - Day 97

ç»Ÿè®¡ä»£ç åº“çš„å„ç§æŒ‡æ ‡ï¼š
- æ–‡ä»¶æ•°é‡ã€è¡Œæ•°ï¼ˆä»£ç /æ³¨é‡Š/ç©ºè¡Œï¼‰
- å„è¯­è¨€å æ¯”
- å¤æ‚åº¦ä¼°ç®—
- æ–‡ä»¶å¤§å°ç»Ÿè®¡

Usage:
    python code_stats_analyzer.py [path]
    python code_stats_analyzer.py . --verbose
"""

import os
import sys
from pathlib import Path
from collections import defaultdict
from datetime import datetime

# æ”¯æŒçš„æ–‡ä»¶æ‰©å±•åå’Œå¯¹åº”è¯­è¨€
LANGUAGE_MAP = {
    '.py': 'Python',
    '.js': 'JavaScript',
    '.ts': 'TypeScript',
    '.html': 'HTML',
    '.css': 'CSS',
    '.json': 'JSON',
    '.md': 'Markdown',
    '.txt': 'Text',
    '.sh': 'Shell',
    '.bash': 'Bash',
    '.zsh': 'Zsh',
    '.yml': 'YAML',
    '.yaml': 'YAML',
    '.xml': 'XML',
    '.csv': 'CSV',
    '.png': 'PNG',
    '.jpg': 'JPEG',
    '.gif': 'GIF',
    '.svg': 'SVG',
    '.ico': 'Icon',
    '.pyc': 'Python Bytecode',
    '.db': 'Database',
    '.log': 'Log',
    '.gitignore': 'Git Ignore',
    '.env': 'Environment',
}

# ä»£ç æ–‡ä»¶æ‰©å±•åï¼ˆç”¨äºç»Ÿè®¡ä»£ç è¡Œæ•°ï¼‰
CODE_EXTENSIONS = {
    '.py', '.js', '.ts', '.html', '.css', '.sh', '.bash', '.zsh',
    '.yml', '.yaml', '.xml', '.json', '.md', '.txt'
}

def get_language(filename):
    """æ ¹æ®æ–‡ä»¶åè·å–è¯­è¨€ç±»å‹"""
    ext = Path(filename).suffix.lower()
    return LANGUAGE_MAP.get(ext, 'Other')

def is_code_file(filename):
    """åˆ¤æ–­æ˜¯å¦ä¸ºä»£ç æ–‡ä»¶"""
    ext = Path(filename).suffix.lower()
    return ext in CODE_EXTENSIONS

def count_lines(content):
    """ç»Ÿè®¡ä»£ç è¡Œæ•°ã€æ³¨é‡Šè¡Œã€ç©ºè¡Œ"""
    lines = content.split('\n')
    total = len(lines)
    code_lines = 0
    comment_lines = 0
    blank_lines = 0
    
    in_multiline_comment = False
    
    for line in lines:
        stripped = line.strip()
        
        # æ£€æŸ¥å¤šè¡Œæ³¨é‡Šå¼€å§‹/ç»“æŸ
        if '"""' in stripped or "'''" in stripped:
            if in_multiline_comment:
                in_multiline_comment = False
            else:
                in_multiline_comment = True
            comment_lines += 1
            continue
        
        if in_multiline_comment:
            comment_lines += 1
            continue
        
        # ç©ºè¡Œ
        if not stripped:
            blank_lines += 1
            continue
        
        # å•è¡Œæ³¨é‡Š
        if stripped.startswith('#') or stripped.startswith('//'):
            comment_lines += 1
            continue
        
        code_lines += 1
    
    return total, code_lines, comment_lines, blank_lines

def estimate_complexity(content):
    """ä¼°ç®—ä»£ç å¤æ‚åº¦ï¼ˆåŸºäºåˆ†æ”¯å’Œå¾ªç¯ï¼‰"""
    complexity = 1  # åŸºç¡€å¤æ‚åº¦
    
    keywords = ['if', 'elif', 'else', 'for', 'while', 'and', 'or', 'try', 'except', 'finally', 'with']
    for keyword in keywords:
        complexity += content.lower().count(f' {keyword} ')
        complexity += content.lower().count(f'{keyword}(')
    
    return complexity

def analyze_path(path, verbose=False):
    """åˆ†ææŒ‡å®šè·¯å¾„çš„ä»£ç ç»Ÿè®¡"""
    path = Path(path)
    
    if not path.exists():
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}")
        return
    
    stats = {
        'total_files': 0,
        'code_files': 0,
        'total_lines': 0,
        'code_lines': 0,
        'comment_lines': 0,
        'blank_lines': 0,
        'total_size': 0,
        'language_stats': defaultdict(lambda: {'files': 0, 'lines': 0, 'size': 0}),
        'complexity_total': 0,
    }
    
    files_analyzed = []
    
    for file_path in path.rglob('*'):
        if file_path.is_file():
            stats['total_files'] += 1
            
            try:
                size = file_path.stat().st_size
                stats['total_size'] += size
                
                rel_path = file_path.relative_to(path)
                ext = file_path.suffix.lower()
                lang = get_language(file_path.name)
                
                stats['language_stats'][lang]['files'] += 1
                stats['language_stats'][lang]['size'] += size
                
                if is_code_file(file_path.name):
                    stats['code_files'] += 1
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        total, code, comment, blank = count_lines(content)
                        stats['total_lines'] += total
                        stats['code_lines'] += code
                        stats['comment_lines'] += comment
                        stats['blank_lines'] += blank
                        
                        stats['language_stats'][lang]['lines'] += total
                        
                        complexity = estimate_complexity(content)
                        stats['complexity_total'] += complexity
                        
                        if verbose:
                            files_analyzed.append({
                                'path': str(rel_path),
                                'lines': total,
                                'code': code,
                                'lang': lang
                            })
                    except Exception as e:
                        pass  # è·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶æˆ–æ— æ³•è¯»å–çš„æ–‡ä»¶
                        
            except Exception as e:
                pass  # è·³è¿‡æƒé™é—®é¢˜ç­‰
    
    return stats, files_analyzed

def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024
    return f"{size_bytes:.2f} TB"

def print_stats(stats, files_analyzed=None, verbose=False):
    """æ‰“å°ç»Ÿè®¡ç»“æœ"""
    print("\n" + "="*60)
    print("ğŸ“Š ä»£ç ç»Ÿè®¡æŠ¥å‘Š")
    print("="*60)
    
    print(f"\nğŸ“ æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    print(f"ğŸ“ ä»£ç æ–‡ä»¶æ•°: {stats['code_files']}")
    print(f"ğŸ’¾ æ€»å¤§å°: {format_size(stats['total_size'])}")
    
    print(f"\nğŸ“ æ€»è¡Œæ•°: {stats['total_lines']:,}")
    print(f"   - ä»£ç è¡Œ: {stats['code_lines']:,} ({stats['code_lines']/max(1,stats['total_lines'])*100:.1f}%)")
    print(f"   - æ³¨é‡Šè¡Œ: {stats['comment_lines']:,} ({stats['comment_lines']/max(1,stats['total_lines'])*100:.1f}%)")
    print(f"   - ç©ºè¡Œ: {stats['blank_lines']:,} ({stats['blank_lines']/max(1,stats['total_lines'])*100:.1f}%)")
    
    print(f"\nğŸ§  ä¼°ç®—æ€»å¤æ‚åº¦: {stats['complexity_total']}")
    print(f"   å¹³å‡å¤æ‚åº¦: {stats['complexity_total']/max(1, stats['code_files']):.2f}")
    
    print("\nğŸŒ è¯­è¨€åˆ†å¸ƒ:")
    print("-"*50)
    
    sorted_langs = sorted(stats['language_stats'].items(), 
                         key=lambda x: x[1]['lines'], reverse=True)
    
    for lang, lang_stats in sorted_langs:
        if lang_stats['files'] > 0:
            pct = lang_stats['lines'] / max(1, stats['total_lines']) * 100
            bar = 'â–ˆ' * int(pct / 2) + 'â–‘' * (50 - int(pct / 2))
            print(f"  {lang:15} | {bar[:25]:25} | {lang_stats['files']:3} æ–‡ä»¶ | {lang_stats['lines']:5,} è¡Œ")
    
    if verbose and files_analyzed:
        print(f"\nğŸ“„ è¯¦ç»†æ–‡ä»¶åˆ—è¡¨ (Top 20):")
        print("-"*60)
        sorted_files = sorted(files_analyzed, key=lambda x: x['lines'], reverse=True)[:20]
        for f in sorted_files:
            print(f"  {f['lines']:5} è¡Œ | {f['lang']:12} | {f['path']}")
    
    print("\n" + "="*60)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ä»£ç ç»Ÿè®¡åˆ†æä»ª')
    parser.add_argument('path', nargs='?', default='.', help='è¦åˆ†æçš„è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†æ¨¡å¼')
    parser.add_argument('--json', '-j', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    
    args = parser.parse_args()
    
    print(f"\nğŸ” æ­£åœ¨åˆ†æ: {os.path.abspath(args.path)}")
    
    stats, files_analyzed = analyze_path(args.path, args.verbose)
    
    if args.json:
        import json
        # è½¬æ¢defaultdictä¸ºæ™®é€šdict
        stats['language_stats'] = {k: dict(v) for k, v in stats['language_stats'].items()}
        print(json.dumps(stats, indent=2, ensure_ascii=False))
    else:
        print_stats(stats, files_analyzed, args.verbose)
    
    print(f"\nâœ¨ åˆ†æå®Œæˆï¼")

if __name__ == '__main__':
    main()

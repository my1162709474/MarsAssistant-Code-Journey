#!/usr/bin/env python3
"""
ğŸ¯ Day 39: å®æ—¶æ–‡ä»¶ç³»ç»Ÿç›‘æ§å™¨
==============================
å®æ—¶ç›‘æ§ç›®å½•/æ–‡ä»¶çš„åˆ›å»ºã€ä¿®æ”¹ã€åˆ é™¤äº‹ä»¶
æ”¯æŒæ­£åˆ™è¿‡æ»¤ã€å®šæ—¶æŠ¥å‘Šã€å¤šç§è¾“å‡ºæ ¼å¼

åŠŸèƒ½ç‰¹æ€§:
- ğŸ” å®æ—¶æ–‡ä»¶äº‹ä»¶ç›‘æ§
- ğŸ“Š å®šæ—¶æ±‡æ€»æŠ¥å‘Š
- ğŸ¯ æ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤
- ğŸ“ˆ äº‹ä»¶ç»Ÿè®¡åˆ†æ
- ğŸ’¾ æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼

ä½œè€…: AI Assistant
æ—¥æœŸ: 2026-02-02
"""

import os
import sys
import time
import json
import re
import argparse
import threading
import statistics
from datetime import datetime, timedelta
from collections import defaultdict, deque
from pathlib import Path
from enum import Enum
from typing import Optional, Callable, Dict, List, Set, Any
import hashlib


class EventType(Enum):
    """æ–‡ä»¶äº‹ä»¶ç±»å‹"""
    CREATED = "created"
    MODIFIED = "modified"
    DELETED = "deleted"
    MOVED = "moved"
    ACCESSED = "accessed"


class FileMonitor:
    """æ–‡ä»¶ç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self, 
                 path: str,
                 recursive: bool = True,
                 event_types: Optional[Set[EventType]] = None,
                 pattern: Optional[str] = None,
                 ignore_pattern: Optional[str] = None):
        self.path = Path(path)
        self.recursive = recursive
        self.event_types = event_types or {EventType.CREATED, EventType.MODIFIED, EventType.DELETED}
        self.pattern = re.compile(pattern) if pattern else None
        self.ignore_pattern = re.compile(ignore_pattern) if ignore_pattern else None
        
        self.events: deque = deque(maxlen=10000)
        self.stats: Dict[str, Any] = {
            'total_events': 0,
            'by_type': defaultdict(int),
            'by_extension': defaultdict(int),
            'by_hour': defaultdict(int),
            'largest_files': [],
            'most_active_files': defaultdict(int),
            'start_time': None,
            'end_time': None
        }
        self._running = False
        self._lock = threading.Lock()
        
    def _should_watch(self, filepath: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ç›‘æ§è¯¥æ–‡ä»¶"""
        # æ£€æŸ¥å¿½ç•¥æ¨¡å¼
        if self.ignore_pattern and self.ignore_pattern.search(str(filepath)):
            return False
        
        # æ£€æŸ¥åŒ…å«æ¨¡å¼
        if self.pattern and not self.pattern.search(str(filepath)):
            return False
        
        return True
    
    def _get_event_type(self, old_state: Optional[Dict], new_state: Optional[Dict]) -> Optional[EventType]:
        """ç¡®å®šäº‹ä»¶ç±»å‹"""
        if old_state is None and new_state is not None:
            return EventType.CREATED
        elif old_state is not None and new_state is None:
            return EventType.DELETED
        elif old_state is not None and new_state is not None:
            if old_state['size'] != new_state['size'] or old_state['mtime'] != new_state['mtime']:
                return EventType.MODIFIED
        return None
    
    def _get_file_state(self, filepath: Path) -> Optional[Dict]:
        """è·å–æ–‡ä»¶å½“å‰çŠ¶æ€"""
        try:
            if filepath.is_file():
                stat = filepath.stat()
                return {
                    'size': stat.st_size,
                    'mtime': stat.st_mtime,
                    'ctime': stat.st_ctime,
                    'atime': stat.st_atime,
                    'hash': self._calculate_hash(filepath)
                }
        except (PermissionError, FileNotFoundError):
            pass
        return None
    
    def _calculate_hash(self, filepath: Path, chunk_size: int = 8192) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        try:
            hasher = hashlib.md5()
            with open(filepath, 'rb') as f:
                while chunk := f.read(chunk_size):
                    hasher.update(chunk)
            return hasher.hexdigest()[:16]
        except Exception:
            return ""
    
    def _compare_states(self, old_states: Dict[str, Dict], new_states: Dict[str, Dict]) -> List[Dict]:
        """æ¯”è¾ƒæ–‡ä»¶çŠ¶æ€å˜åŒ–"""
        events = []
        
        # æ£€æŸ¥æ–°å»ºå’Œä¿®æ”¹
        for filepath, new_state in new_states.items():
            old_state = old_states.get(filepath)
            event_type = self._get_event_type(old_state, new_state)
            
            if event_type and self._should_watch(Path(filepath)):
                events.append({
                    'type': event_type.value,
                    'path': filepath,
                    'timestamp': datetime.now().isoformat(),
                    'size': new_state.get('size', 0),
                    'size_formatted': self._format_size(new_state.get('size', 0))
                })
        
        # æ£€æŸ¥åˆ é™¤
        for filepath, old_state in old_states.items():
            if filepath not in new_states:
                if self._should_watch(Path(filepath)):
                    events.append({
                        'type': EventType.DELETED.value,
                        'path': filepath,
                        'timestamp': datetime.now().isoformat(),
                        'size': old_state.get('size', 0),
                        'size_formatted': self._format_size(old_state.get('size', 0))
                    })
        
        return events
    
    def _format_size(self, size: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f}{unit}"
            size /= 1024
        return f"{size:.1f}TB"
    
    def scan_directory(self) -> Dict[str, Dict]:
        """æ‰«æç›®å½•è·å–æ‰€æœ‰æ–‡ä»¶çŠ¶æ€"""
        states = {}
        
        if self.path.is_file():
            files = [self.path]
        else:
            files = self.path.rglob('*') if self.recursive else self.path.glob('*')
        
        for filepath in files:
            if filepath.is_file():
                state = self._get_file_state(filepath)
                if state:
                    states[str(filepath)] = state
        
        return states
    
    def start(self, interval: float = 1.0, callback: Optional[Callable] = None):
        """å¼€å§‹ç›‘æ§"""
        self._running = True
        self.stats['start_time'] = datetime.now()
        
        old_states = self.scan_directory()
        
        def monitor_loop():
            while self._running:
                try:
                    time.sleep(interval)
                    new_states = self.scan_directory()
                    events = self._compare_states(old_states, new_states)
                    
                    if events:
                        with self._lock:
                            for event in events:
                                self.events.append(event)
                                self._update_stats(event)
                        
                        if callback:
                            callback(events)
                    
                    old_states = new_states
                    
                except Exception as e:
                    print(f"ç›‘æ§é”™è¯¯: {e}", file=sys.stderr)
        
        self._thread = threading.Thread(target=monitor_loop, daemon=True)
        self._thread.start()
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self._running = False
        self.stats['end_time'] = datetime.now()
        if hasattr(self, '_thread'):
            self._thread.join(timeout=2)
    
    def _update_stats(self, event: Dict):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['total_events'] += 1
        self.stats['by_type'][event['type']] += 1
        
        # æŒ‰æ‰©å±•åç»Ÿè®¡
        ext = Path(event['path']).suffix.lower()
        self.stats['by_extension'][ext or '(æ— )'] += 1
        
        # æŒ‰å°æ—¶ç»Ÿè®¡
        hour = datetime.fromisoformat(event['timestamp']).hour
        self.stats['by_hour'][hour] += 1
        
        # æ´»è·ƒæ–‡ä»¶ç»Ÿè®¡
        self.stats['most_active_files'][event['path']] += 1
        
        # å¤§æ–‡ä»¶è¿½è¸ª
        size = event.get('size', 0)
        self.stats['largest_files'].append({
            'path': event['path'],
            'size': size,
            'type': event['type']
        })
        self.stats['largest_files'].sort(key=lambda x: x['size'], reverse=True)
        self.stats['largest_files'] = self.stats['largest_files'][:10]
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            stats = dict(self.stats)
        
        # è®¡ç®—è¿è¡Œæ—¶é•¿
        if stats['start_time']:
            if stats['end_time']:
                duration = stats['end_time'] - stats['start_time']
            else:
                duration = datetime.now() - stats['start_time']
            stats['duration_seconds'] = duration.total_seconds()
        
        # è®¡ç®—äº‹ä»¶ç‡
        if stats.get('duration_seconds', 0) > 0:
            stats['events_per_second'] = stats['total_events'] / stats['duration_seconds']
        
        return stats
    
    def get_recent_events(self, count: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘äº‹ä»¶"""
        with self._lock:
            return list(self.events)[-count:]


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_summary(stats: Dict, events: List[Dict]) -> str:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        lines = [
            "=" * 60,
            "ğŸ“Š æ–‡ä»¶ç³»ç»Ÿç›‘æ§æŠ¥å‘Š",
            "=" * 60,
            f"â° ç›‘æ§æ—¶é•¿: {stats.get('duration_seconds', 0):.1f} ç§’",
            f"ğŸ“ æ€»äº‹ä»¶æ•°: {stats['total_events']}",
            f"âš¡ äº‹ä»¶é€Ÿç‡: {stats.get('events_per_second', 0):.2f} äº‹ä»¶/ç§’",
            "",
            "ğŸ“ˆ äº‹ä»¶ç±»å‹åˆ†å¸ƒ:",
        ]
        
        for event_type, count in stats['by_type'].items():
            percentage = (count / stats['total_events'] * 100) if stats['total_events'] > 0 else 0
            bar = 'â–ˆ' * int(percentage / 5)
            lines.append(f"  {event_type:12s}: {count:5d} ({percentage:5.1f}%) {bar}")
        
        lines.extend(["", "ğŸ“ æ–‡ä»¶æ‰©å±•ååˆ†å¸ƒ:"])
        for ext, count in sorted(stats['by_extension'].items(), key=lambda x: x[1], reverse=True)[:5]:
            lines.append(f"  {ext:15s}: {count:5d}")
        
        lines.extend(["", "ğŸ”¥ æœ€æ´»è·ƒæ–‡ä»¶ (Top 5):"])
        for path, count in sorted(stats['most_active_files'].items(), key=lambda x: x[1], reverse=True)[:5]:
            lines.append(f"  {count:3d} æ¬¡ - {path}")
        
        if events:
            lines.extend(["", "ğŸ“‹ æœ€è¿‘äº‹ä»¶:"])
            for event in events[-5:]:
                emoji = {'created': 'ğŸ†•', 'modified': 'ğŸ“', 'deleted': 'ğŸ—‘ï¸', 'moved': 'â¡ï¸', 'accessed': 'ğŸ‘ï¸'}
                e = emoji.get(event['type'], 'ğŸ“„')
                lines.append(f"  {e} {event['type']:8s} - {event['path']}")
        
        lines.append("=" * 60)
        return '\n'.join(lines)
    
    @staticmethod
    def generate_json(stats: Dict, events: List[Dict]) -> str:
        """ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š"""
        return json.dumps({
            'timestamp': datetime.now().isoformat(),
            'statistics': stats,
            'recent_events': events
        }, indent=2, ensure_ascii=False)


def create_sample_monitor():
    """åˆ›å»ºç¤ºä¾‹æ–‡ä»¶ç”¨äºæµ‹è¯•"""
    sample_dir = Path("/tmp/file_monitor_test")
    sample_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    test_files = [
        sample_dir / "test1.txt",
        sample_dir / "test2.txt", 
        sample_dir / "data.json",
        sample_dir / "notes.md"
    ]
    
    for i, f in enumerate(test_files):
        f.write_text(f"æµ‹è¯•æ–‡ä»¶ {i+1}\nåˆ›å»ºæ—¶é—´: {datetime.now()}\n")
    
    return sample_dir


def interactive_mode():
    """äº¤äº’å¼ç›‘æ§æ¨¡å¼"""
    print("ğŸ¯ æ–‡ä»¶ç³»ç»Ÿç›‘æ§å™¨ - äº¤äº’æ¨¡å¼")
    print("=" * 50)
    
    path = input("ç›‘æ§è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨ /tmp): ").strip() or "/tmp"
    recursive = input("é€’å½’ç›‘æ§? (y/n, é»˜è®¤y): ").strip().lower() != 'n'
    interval = float(input("æ‰«æé—´éš”ç§’æ•° (é»˜è®¤1.0): ").strip() or "1.0")
    
    if not os.path.exists(path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}")
        return
    
    monitor = FileMonitor(path, recursive=recursive)
    
    def on_events(events):
        print(f"\nğŸ“¥ æ£€æµ‹åˆ° {len(events)} ä¸ªäº‹ä»¶:")
        for event in events[-3:]:  # åªæ˜¾ç¤ºæœ€è¿‘3ä¸ª
            emoji = {'created': 'ğŸ†•', 'modified': 'ğŸ“', 'deleted': 'ğŸ—‘ï¸'}
            e = emoji.get(event['type'], 'ğŸ“„')
            print(f"  {e} {event['type']:8s} | {event['size_formatted']:8s} | {event['path'][-50:]}")
    
    print(f"\nâœ… å¼€å§‹ç›‘æ§: {path}")
    print("ğŸ’¡ æŒ‰ Ctrl+C åœæ­¢ç›‘æ§å¹¶ç”ŸæˆæŠ¥å‘Š\n")
    
    monitor.start(interval=interval, callback=on_events)
    
    try:
        while True:
            time.sleep(5)
            stats = monitor.get_stats()
            print(f"\râ±ï¸ è¿è¡Œ {stats.get('duration_seconds', 0):.0f}s | ğŸ“Š {stats['total_events']} äº‹ä»¶ | âš¡ {stats.get('events_per_second', 0):.1f}/s", end='', flush=True)
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ åœæ­¢ç›‘æ§...")
        monitor.stop()
        
        events = monitor.get_recent_events(50)
        stats = monitor.get_stats()
        
        print("\n" + ReportGenerator.generate_summary(stats, events))


def daemon_mode(path: str, output: str = "text"):
    """å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ - æŒç»­ç›‘æ§å¹¶å®šæœŸæŠ¥å‘Š"""
    print(f"ğŸš€ å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼: {path}")
    
    if not os.path.exists(path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}")
        return
    
    monitor = FileMonitor(path)
    monitor.start(interval=1.0)
    
    try:
        while True:
            time.sleep(60)  # æ¯åˆ†é’ŸæŠ¥å‘Šä¸€æ¬¡
            stats = monitor.get_stats()
            events = monitor.get_recent_events(100)
            
            if output == "json":
                print(ReportGenerator.generate_json(stats, events))
            else:
                print(f"\n[{datetime.now().strftime('%H:%M:%S')}] " + ReportGenerator.generate_summary(stats, events))
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ åœæ­¢ç›‘æ§...")
        monitor.stop()
        print("\n" + ReportGenerator.generate_summary(monitor.get_stats(), monitor.get_recent_events()))


def watch_created_files():
    """ä»…ç›‘æ§æ–°åˆ›å»ºçš„æ–‡ä»¶"""
    path = input("ç›‘æ§è·¯å¾„: ").strip()
    if not os.path.exists(path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}")
        return
    
    print(f"ğŸ‘€ ä»…ç›‘æ§æ–°åˆ›å»ºçš„æ–‡ä»¶: {path}")
    
    existing_files = set()
    for f in Path(path).rglob('*'):
        if f.is_file():
            existing_files.add(str(f))
    
    monitor = FileMonitor(path, event_types={EventType.CREATED})
    created_files = []
    
    def on_events(events):
        for event in events:
            if event['type'] == 'created':
                created_files.append(event)
                print(f"ğŸ†• æ–°æ–‡ä»¶: {event['path']} ({event['size_formatted']})")
    
    monitor.start(interval=0.5, callback=on_events)
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        monitor.stop()
        print(f"\nğŸ“Š å…±å‘ç° {len(created_files)} ä¸ªæ–°æ–‡ä»¶")


def main():
    parser = argparse.ArgumentParser(
        description="ğŸ¯ å®æ—¶æ–‡ä»¶ç³»ç»Ÿç›‘æ§å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s                              # äº¤äº’æ¨¡å¼
  %(prog)s --path /tmp --daemon         # å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼
  %(prog)s --path /tmp --watch-new      # ä»…ç›‘æ§æ–°æ–‡ä»¶
  %(prog)s --path /tmp --report 60      # æ¯60ç§’è¾“å‡ºæŠ¥å‘Š
  %(prog)s --create-sample              # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
        """
    )
    
    parser.add_argument('-p', '--path', default='/tmp', help='ç›‘æ§è·¯å¾„ (é»˜è®¤: /tmp)')
    parser.add_argument('-i', '--interval', type=float, default=1.0, help='æ‰«æé—´éš”ç§’æ•° (é»˜è®¤: 1.0)')
    parser.add_argument('-r', '--recursive', action='store_true', help='é€’å½’ç›‘æ§å­ç›®å½•')
    parser.add_argument('--pattern', help='æ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤æ¨¡å¼')
    parser.add_argument('--ignore', help='æ­£åˆ™è¡¨è¾¾å¼å¿½ç•¥æ¨¡å¼')
    
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument('--daemon', action='store_true', help='å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ (æŒç»­ç›‘æ§)')
    mode_group.add_argument('--watch-new', action='store_true', help='ä»…ç›‘æ§æ–°åˆ›å»ºçš„æ–‡ä»¶')
    mode_group.add_argument('--report', type=int, metavar='SECONDS', help='å®šæ—¶æŠ¥å‘Šæ¨¡å¼')
    mode_group.add_argument('--create-sample', action='store_true', help='åˆ›å»ºæµ‹è¯•æ ·æœ¬ç›®å½•')
    mode_group.add_argument('--once', action='store_true', help='å•æ¬¡æ‰«æå¯¹æ¯”')
    
    parser.add_argument('--output', choices=['text', 'json'], default='text', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--json', action='store_true', help='JSONè¾“å‡º (ç­‰åŒäº --output json)')
    
    args = parser.parse_args()
    
    if args.json:
        args.output = 'json'
    
    if args.create_sample:
        sample_dir = create_sample_dir()
        print(f"âœ… æµ‹è¯•ç›®å½•: {sample_dir}")
        print("ğŸ“ ç›®å½•ä¸­æœ‰4ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œå¯ä»¥å¼€å§‹ç›‘æ§æµ‹è¯•")
        return
    
    path = args.path
    if not os.path.exists(path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}")
        sys.exit(1)
    
    if args.watch_new:
        watch_created_files()
        return
    
    if args.daemon or args.report:
        daemon_mode(path, args.output)
        return
    
    if args.once:
        # å•æ¬¡æ‰«ææ¨¡å¼
        print(f"ğŸ” å•æ¬¡æ‰«æ: {path}")
        monitor = FileMonitor(path, recursive=args.recursive, pattern=args.pattern, ignore_pattern=args.ignore)
        states = monitor.scan_directory()
        print(f"ğŸ“ å‘ç° {len(states)} ä¸ªæ–‡ä»¶")
        for f, state in list(states.items())[:10]:
            print(f"  {f}: {monitor._format_size(state['size'])}")
        return
    
    # é»˜è®¤äº¤äº’æ¨¡å¼
    interactive_mode()


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
Data Cleaner - æ•°æ®æ¸…æ´—å·¥å…·
æ”¯æŒCSV/JSONæ ¼å¼ï¼Œå¤„ç†ç¼ºå¤±å€¼ï¼Œæ•°æ®æ ¼å¼è½¬æ¢ï¼ŒåŸºç¡€ç»Ÿè®¡
"""

import csv
import json
import re
from typing import Any, Dict, List, Optional, Union
from statistics import mean, median


class DataCleaner:
    """æ•°æ®æ¸…æ´—ä¸»ç±»"""
    
    def __init__(self, data: Optional[Union[List[Dict], Dict]] = None):
        self.data = data or []
        self.stats = {}
    
    @classmethod
    def from_csv(cls, filepath: str, encoding: str = 'utf-8') -> 'DataCleaner':
        """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®"""
        with open(filepath, 'r', encoding=encoding) as f:
            reader = csv.DictReader(f)
            data = list(reader)
        return cls(data)
    
    @classmethod
    def from_json(cls, filepath: str, encoding: str = 'utf-8') -> 'DataCleaner':
        """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
        with open(filepath, 'r', encoding=encoding) as f:
            data = json.load(f)
        if isinstance(data, dict):
            data = [data]
        return cls(data)
    
    def to_json(self, filepath: str = None) -> str:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        result = json.dumps(self.data, ensure_ascii=False, indent=2)
        if filepath:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(result)
        return result
    
    def handle_missing(self, strategy: str = 'remove', 
                       fill_value: Any = None, 
                       columns: List[str] = None) -> 'DataCleaner':
        """
        å¤„ç†ç¼ºå¤±å€¼
        - remove: åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
        - fill: å¡«å……æŒ‡å®šå€¼
        - fill_mean: æ•°å€¼åˆ—å¡«å……å¹³å‡å€¼
        """
        columns = columns or []
        
        if strategy == 'remove':
            self.data = [row for row in self.data 
                        if all(row.get(col) for col in columns)] if columns else                        [row for row in self.data if any(row.values())]
        
        elif strategy == 'fill':
            self.data = [{col: (row.get(col) if row.get(col) else fill_value) 
                         for col in (columns or row.keys())} for row in self.data]
        
        elif strategy == 'fill_mean':
            num_cols = columns or [k for k in self.data[0].keys() 
                                   if self.data[0].get(k, '').replace('.','').replace('-','').isdigit()]
            for col in num_cols:
                values = [float(row[col]) for row in self.data if row.get(col)]
                if values:
                    avg = mean(values)
                    for row in self.data:
                        if not row.get(col):
                            row[col] = str(round(avg, 2))
        return self
    
    def normalize_text(self, columns: List[str] = None, 
                       lowercase: bool = True,
                       remove_special: bool = True) -> 'DataCleaner':
        """æ–‡æœ¬æ ‡å‡†åŒ–"""
        columns = columns or []
        
        for row in self.data:
            for col in columns or row.keys():
                if isinstance(row.get(col), str):
                    text = row[col]
                    if lowercase:
                        text = text.lower()
                    if remove_special:
                        text = re.sub(r'[^\w\s]', '', text)
                    row[col] = text.strip()
        return self
    
    def remove_duplicates(self, key: str = None) -> 'DataCleaner':
        """åˆ é™¤é‡å¤é¡¹"""
        if key:
            seen = set()
            self.data = [row for row in self.data 
                        if not (row.get(key) in seen or seen.add(row.get(key)))]
        else:
            seen = set()
            self.data = [row for row in self.data 
                        if not (json.dumps(sorted(row.items())) in seen or 
                               seen.add(json.dumps(sorted(row.items()))))]
        return self
    
    def basic_stats(self) -> Dict[str, Any]:
        """åŸºç¡€ç»Ÿè®¡åˆ†æ"""
        if not self.data:
            return {}
        
        self.stats = {
            'total_rows': len(self.data),
            'columns': list(self.data[0].keys()) if self.data else [],
            'numeric_columns': [],
            'missing_values': {}
        }
        
        for col in self.stats['columns']:
            values = [row.get(col) for row in self.data if row.get(col)]
            numeric_values = []
            for v in values:
                try:
                    numeric_values.append(float(v))
                except (ValueError, TypeError):
                    pass
            
            if len(numeric_values) > len(values) * 0.5:
                self.stats['numeric_columns'].append(col)
                if numeric_values:
                    self.stats[col] = {
                        'min': min(numeric_values),
                        'max': max(numeric_values),
                        'mean': round(mean(numeric_values), 2),
                        'median': round(median(numeric_values), 2)
                    }
            
            missing = sum(1 for row in self.data if not row.get(col))
            if missing > 0:
                self.stats['missing_values'][col] = missing
        
        return self.stats
    
    def filter_by_value(self, column: str, 
                       operator: str, 
                       value: Any) -> 'DataCleaner':
        """æŒ‰å€¼è¿‡æ»¤æ•°æ®"""
        operators = {
            '>': lambda x, y: float(x) > float(y),
            '<': lambda x, y: float(x) < float(y),
            '>=': lambda x, y: float(x) >= float(y),
            '<=': lambda x, y: float(x) <= float(y),
            '==': lambda x, y: x == y,
            '!=': lambda x, y: x != y,
            'contains': lambda x, y: y.lower() in x.lower() if isinstance(x, str) else False
        }
        
        op_func = operators.get(operator, operators['=='])
        self.data = [row for row in self.data if op_func(row.get(column), value)]
        return self


def clean_csv(input_path: str, output_path: str = None, **kwargs) -> DataCleaner:
    """ä¸€é”®æ¸…æ´—CSV"""
    cleaner = DataCleaner.from_csv(input_path)
    if 'missing_strategy' in kwargs:
        cleaner.handle_missing(kwargs['missing_strategy'], kwargs.get('fill_value'))
    if 'normalize_columns' in kwargs:
        cleaner.normalize_text(kwargs['normalize_columns'])
    if 'dedup_key' in kwargs:
        cleaner.remove_duplicates(kwargs['dedup_key'])
    
    result = cleaner.to_json(output_path)
    cleaner.basic_stats()
    return cleaner, result


if __name__ == '__main__':
    print("ğŸ§¹ Data Cleaner - æ•°æ®æ¸…æ´—å·¥å…·")
    print("=" * 40)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    sample_data = [
        {"name": "Alice", "age": "25", "city": "Beijing"},
        {"name": "Bob", "age": "", "city": "shanghai"},
        {"name": "Alice", "age": "25", "city": "beijing"},
        {"name": "Charlie", "age": "30", "city": "Guangzhou"},
    ]
    
    cleaner = DataCleaner(sample_data)
    print(f"åŸå§‹æ•°æ®: {len(cleaner.data)} æ¡")
    
    # å¤„ç†ç¼ºå¤±å€¼
    cleaner.handle_missing('fill_mean', '0', ['age'])
    print(f"ç¼ºå¤±å€¼å¤„ç†å: {len(cleaner.data)} æ¡")
    
    # æ–‡æœ¬æ ‡å‡†åŒ–
    cleaner.normalize_text(['city'], lowercase=True)
    print(f"åŸå¸‚æ ‡å‡†åŒ–: {cleaner.data[0]['city']}")
    
    # å»é‡
    cleaner.remove_duplicates('name')
    print(f"å»é‡å: {len(cleaner.data)} æ¡")
    
    # ç»Ÿè®¡
    stats = cleaner.basic_stats()
    print(f"\nç»Ÿè®¡ä¿¡æ¯: {json.dumps(stats, indent=2)}")

#!/usr/bin/env python3
"""
API Response Cache Manager - APIå“åº”ç¼“å­˜ç®¡ç†å™¨
=================================================

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„APIå“åº”ç¼“å­˜å·¥å…·ï¼Œæ”¯æŒï¼š
- TTL (Time-To-Live) è¿‡æœŸæœºåˆ¶
- LRU (Least Recently Used) æ·˜æ±°ç­–ç•¥
- ç£ç›˜æŒä¹…åŒ–
- ç»Ÿè®¡ä¿¡æ¯è¿½è¸ª
- çº¿ç¨‹å®‰å…¨

Author: MarsAssistant
Day: 78
"""

import hashlib
import json
import os
import pickle
import threading
import time
from collections import OrderedDict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Optional, Tuple


@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str
    value: Any
    created_at: float
    expires_at: float
    access_count: int = 0
    last_accessed: float = field(default_factory=time.time)
    
    def is_expired(self, current_time: Optional[float] = None) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        if current_time is None:
            current_time = time.time()
        return current_time > self.expires_at
    
    def is_valid(self, current_time: Optional[float] = None) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ•ˆ"""
        return not self.is_expired(current_time)


class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    def __init__(self):
        self.hits = 0
        self.misses = 0
        self.sets = 0
        self.deletes = 0
        self.expirations = 0
        self.evictions = 0
        self._lock = threading.RLock()
    
    def record_hit(self):
        with self._lock:
            self.hits += 1
    
    def record_miss(self):
        with self._lock:
            self.misses += 1
    
    def record_set(self):
        with self._lock:
            self.sets += 1
    
    def record_delete(self):
        with self._lock:
            self.deletes += 1
    
    def record_expiration(self):
        with self._lock:
            self.expirations += 1
    
    def record_eviction(self):
        with self._lock:
            self.evictions += 1
    
    def get_hit_rate(self) -> float:
        """è·å–å‘½ä¸­ç‡"""
        total = self.hits + self.misses
        if total == 0:
            return 0.0
        return self.hits / total
    
    def get_summary(self) -> dict:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        with self._lock:
            return {
                "hits": self.hits,
                "misses": self.misses,
                "sets": self.sets,
                "deletes": self.deletes,
                "expirations": self.expirations,
                "evictions": self.evictions,
                "hit_rate": f"{self.get_hit_rate():.2%}",
                "total_requests": self.hits + self.misses
            }


class APICacheManager:
    """APIå“åº”ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(
        self,
        cache_dir: str = "./cache",
        max_size: int = 1000,
        default_ttl: int = 3600,
        enable_persistence: bool = True,
        persistence_interval: int = 300
    ):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•° (LRUæ·˜æ±°)
            default_ttl: é»˜è®¤TTL (ç§’)
            enable_persistence: æ˜¯å¦å¯ç”¨ç£ç›˜æŒä¹…åŒ–
            persistence_interval: æŒä¹…åŒ–é—´éš” (ç§’)
        """
        self.cache_dir = Path(cache_dir)
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.enable_persistence = enable_persistence
        self.persistence_interval = persistence_interval
        
        # çº¿ç¨‹å®‰å…¨çš„LRUç¼“å­˜
        self._cache: OrderedDict[str, CacheEntry] = OrderedDict()
        self._lock = threading.RLock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = CacheStats()
        
        # æŒä¹…åŒ–ç›¸å…³
        self._last_persist = 0
        self._persist_lock = threading.Lock()
        
        # åˆå§‹åŒ–ç¼“å­˜ç›®å½•
        if self.enable_persistence:
            self.cache_dir.mkdir(parents=True, exist_ok=True)
            self._load_from_disk()
        
        # å¯åŠ¨è‡ªåŠ¨æŒä¹…åŒ–çº¿ç¨‹
        if self.enable_persistence:
            self._start_persistence_thread()
    
    def _generate_key(self, url: str, params: Optional[dict] = None) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = f"{url}:{json.dumps(params, sort_keys=True, default=str)}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        if key not in self._cache:
            return None
        
        entry = self._cache[key]
        
        # æ£€æŸ¥è¿‡æœŸ
        if entry.is_expired():
            del self._cache[key]
            self.stats.record_expiration()
            return None
        
        # æ›´æ–°è®¿é—®ä¿¡æ¯å¹¶ç§»åŠ¨åˆ°æœ«å°¾ (LRU)
        entry.last_accessed = time.time()
        entry.access_count += 1
        self._cache.move_to_end(key)
        
        return entry.value
    
    def get(self, url: str, params: Optional[dict] = None) -> Optional[Any]:
        """
        è·å–ç¼“å­˜çš„å“åº”
        
        Args:
            url: API URL
            params: è¯·æ±‚å‚æ•°
            
        Returns:
            ç¼“å­˜çš„å“åº”ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–å·²è¿‡æœŸåˆ™è¿”å›None
        """
        key = self._generate_key(url, params)
        
        with self._lock:
            value = self._get(key)
            
            if value is not None:
                self.stats.record_hit()
            else:
                self.stats.record_miss()
            
            return value
    
    def set(
        self,
        url: str,
        value: Any,
        params: Optional[dict] = None,
        ttl: Optional[int] = None
    ) -> None:
        """
        ç¼“å­˜å“åº”
        
        Args:
            url: API URL
            value: è¦ç¼“å­˜çš„å€¼
            params: è¯·æ±‚å‚æ•°
            ttl: è¿‡æœŸæ—¶é—´ (ç§’)ï¼Œè¦†ç›–é»˜è®¤TTL
        """
        key = self._generate_key(url, params)
        ttl = ttl or self.default_ttl
        
        current_time = time.time()
        expires_at = current_time + ttl
        
        entry = CacheEntry(
            key=key,
            value=value,
            created_at=current_time,
            expires_at=expires_at
        )
        
        with self._lock:
            # å¦‚æœkeyå·²å­˜åœ¨ï¼Œæ›´æ–°å€¼
            if key in self._cache:
                del self._cache[key]
            
            # æ·»åŠ æ–°æ¡ç›®
            self._cache[key] = entry
            self._cache.move_to_end(key)
            
            # LRUæ·˜æ±°
            while len(self._cache) > self.max_size:
                oldest_key, oldest_entry = self._cache.popitem(last=False)
                self.stats.record_eviction()
            
            self.stats.record_set()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æŒä¹…åŒ–
            if self.enable_persistence:
                current_time = time.time()
                if current_time - self._last_persist > self.persistence_interval:
                    self._persist_to_disk()
    
    def delete(self, url: str, params: Optional[dict] = None) -> bool:
        """
        åˆ é™¤ç¼“å­˜æ¡ç›®
        
        Args:
            url: API URL
            params: è¯·æ±‚å‚æ•°
            
        Returns:
            æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        key = self._generate_key(url, params)
        
        with self._lock:
            if key in self._cache:
                del self._cache[key]
                self.stats.record_delete()
                
                if self.enable_persistence:
                    self._persist_to_disk()
                
                return True
            return False
    
    def clear(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        with self._lock:
            self._cache.clear()
            
            if self.enable_persistence:
                self._persist_to_disk()
    
    def cleanup_expired(self) -> int:
        """
        æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ¡ç›®
        
        Returns:
            æ¸…ç†çš„æ¡ç›®æ•°é‡
        """
        current_time = time.time()
        expired_keys = []
        
        with self._lock:
            for key, entry in self._cache.items():
                if entry.is_expired(current_time):
                    expired_keys.append(key)
            
            for key in expired_keys:
                del self._cache[key]
                self.stats.record_expiration()
            
            if expired_keys:
                if self.enable_persistence:
                    self._persist_to_disk()
        
        return len(expired_keys)
    
    def _persist_to_disk(self) -> None:
        """æŒä¹…åŒ–åˆ°ç£ç›˜"""
        with self._persist_lock:
            try:
                # ä¿å­˜ç¼“å­˜æ•°æ®
                cache_data = {
                    "cache": {k: {
                        "key": v.key,
                        "value": pickle.dumps(v.value),
                        "created_at": v.created_at,
                        "expires_at": v.expires_at,
                        "access_count": v.access_count,
                        "last_accessed": v.last_accessed
                    } for k, v in self._cache.items()},
                    "stats": {
                        "hits": self.stats.hits,
                        "misses": self.stats.misses,
                        "sets": self.stats.sets,
                        "deletes": self.stats.deletes,
                        "expirations": self.stats.expirations,
                        "evictions": self.stats.evictions
                    },
                    "timestamp": time.time()
                }
                
                # å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œç„¶åé‡å‘½åï¼ˆåŸå­æ“ä½œï¼‰
                temp_file = self.cache_dir / "cache_tmp.pkl"
                with open(temp_file, 'wb') as f:
                    pickle.dump(cache_data, f)
                
                (self.cache_dir / "cache.pkl").replace(temp_file)
                
                self._last_persist = time.time()
            except Exception as e:
                print(f"æŒä¹…åŒ–å¤±è´¥: {e}")
    
    def _load_from_disk(self) -> None:
        """ä»ç£ç›˜åŠ è½½"""
        cache_file = self.cache_dir / "cache.pkl"
        
        if not cache_file.exists():
            return
        
        try:
            with open(cache_file, 'rb') as f:
                data = pickle.load(f)
            
            cache_data = data.get("cache", {})
            stats_data = data.get("stats", {})
            timestamp = data.get("timestamp", 0)
            
            current_time = time.time()
            
            with self._lock:
                # åŠ è½½ç¼“å­˜æ¡ç›®
                for key, entry_data in cache_data.items():
                    # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                    if current_time > entry_data["expires_at"]:
                        continue
                    
                    value = pickle.loads(entry_data["value"])
                    entry = CacheEntry(
                        key=entry_data["key"],
                        value=value,
                        created_at=entry_data["created_at"],
                        expires_at=entry_data["expires_at"],
                        access_count=entry_data.get("access_count", 0),
                        last_accessed=entry_data.get("last_accessed", time.time())
                    )
                    self._cache[key] = entry
                
                # åŠ è½½ç»Ÿè®¡ä¿¡æ¯
                if stats_data:
                    self.stats.hits = stats_data.get("hits", 0)
                    self.stats.misses = stats_data.get("misses", 0)
                    self.stats.sets = stats_data.get("sets", 0)
                    self.stats.deletes = stats_data.get("deletes", 0)
                    self.stats.expirations = stats_data.get("expirations", 0)
                    self.stats.evictions = stats_data.get("evictions", 0)
                
                self._last_persist = timestamp
                
        except Exception as e:
            print(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
    
    def _start_persistence_thread(self) -> None:
        """å¯åŠ¨æŒä¹…åŒ–çº¿ç¨‹"""
        def persist_loop():
            while True:
                time.sleep(self.persistence_interval)
                current_time = time.time()
                if current_time - self._last_persist > self.persistence_interval:
                    self._persist_to_disk()
        
        thread = threading.Thread(target=persist_loop, daemon=True)
        thread.start()
    
    def get_stats(self) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            stats = self.stats.get_summary()
            stats.update({
                "current_size": len(self._cache),
                "max_size": self.max_size,
                "utilization": f"{len(self._cache) / self.max_size:.2%}"
            })
            return stats
    
    def get_all_entries(self) -> list:
        """è·å–æ‰€æœ‰ç¼“å­˜æ¡ç›®ä¿¡æ¯"""
        with self._lock:
            current_time = time.time()
            entries = []
            
            for key, entry in self._cache.items():
                remaining_ttl = max(0, entry.expires_at - current_time)
                entries.append({
                    "key": key[:16] + "...",  # æˆªæ–­æ˜¾ç¤º
                    "ttl_remaining": f"{remaining_ttl:.0f}s",
                    "access_count": entry.access_count,
                    "created_at": datetime.fromtimestamp(entry.created_at).isoformat(),
                    "expires_at": datetime.fromtimestamp(entry.expires_at).isoformat()
                })
            
            return entries


def demo():
    """æ¼”ç¤º"""
    print("=" * 60)
    print("API Response Cache Manager - æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
    cache = APICacheManager(
        cache_dir="./demo_cache",
        max_size=10,
        default_ttl=5,
        enable_persistence=True,
        persistence_interval=60
    )
    
    # æµ‹è¯•æ•°æ®
    test_cases = [
        ("https://api.example.com/users", None),
        ("https://api.example.com/posts", {"limit": 10}),
        ("https://api.example.com/comments", {"post_id": 123}),
    ]
    
    print("\nğŸ“ æµ‹è¯•åœºæ™¯1: åŸºæœ¬ç¼“å­˜æ“ä½œ")
    print("-" * 40)
    
    # æ·»åŠ ç¼“å­˜
    for url, params in test_cases:
        data = {"url": url, "params": params, "timestamp": time.time()}
        cache.set(url, data, params)
        print(f"âœ… ç¼“å­˜: {url}")
    
    # è·å–ç¼“å­˜
    print("\nğŸ” æµ‹è¯•åœºæ™¯2: ç¼“å­˜å‘½ä¸­æµ‹è¯•")
    print("-" * 40)
    
    for url, params in test_cases:
        result = cache.get(url, params)
        if result:
            print(f"âœ… å‘½ä¸­: {url}")
        else:
            print(f"âŒ æœªå‘½ä¸­: {url}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 40)
    stats = cache.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # æµ‹è¯•è¿‡æœŸ
    print("\nâ° æµ‹è¯•åœºæ™¯3: TTLè¿‡æœŸæµ‹è¯•")
    print("-" * 40)
    print("ç­‰å¾…6ç§’è®©ç¼“å­˜è¿‡æœŸ...")
    time.sleep(6)
    
    for url, params in test_cases:
        result = cache.get(url, params)
        if result:
            print(f"âœ… ä»ç„¶æœ‰æ•ˆ: {url}")
        else:
            print(f"âŒ å·²è¿‡æœŸ: {url}")
    
    # æ¸…ç†è¿‡æœŸ
    print("\nğŸ§¹ æ¸…ç†è¿‡æœŸæ¡ç›®...")
    cleaned = cache.cleanup_expired()
    print(f"  æ¸…ç†äº† {cleaned} ä¸ªè¿‡æœŸæ¡ç›®")
    
    # å†æ¬¡æ˜¾ç¤ºç»Ÿè®¡
    print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 40)
    stats = cache.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # æ¸…ç†
    cache.clear()
    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    demo()
